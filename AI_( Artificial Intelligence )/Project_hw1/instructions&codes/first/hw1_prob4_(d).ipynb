{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNcUI+84fhX1/mJMn01XXl+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8KypAMu5I0A4"},"outputs":[],"source":["# Import the dependencies\n","from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, SimpleRNN, Embedding\n","from keras.preprocessing import sequence\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","\n","print(\"Imported dependencies.\")"]},{"cell_type":"code","source":["# Define the number of words you want to use\n","max_words = 5000\n","\n","# Define the training and test dataset\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\n","\n","print(\"Created test and training data.\")"],"metadata":{"id":"xXr8SP33JAk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the maximum length of a review\n","max_review_length = 500\n","\n","# Pad the input sequences with 0's to make them all the same length\n","X_train = pad_sequences(X_train, maxlen=max_review_length)\n","X_test = pad_sequences(X_test, maxlen=max_review_length)\n","\n","print(\"Padded the input sequences with 0's to all be the same length.\")"],"metadata":{"id":"mmpMjvaLJCYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define how long the embedding vector will be\n","embedding_vector_length = 32\n","\n","# Define the layers in the model\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_vector_length, input_length=max_review_length))\n","#model.add(SimpleRNN(100, return_sequences=True))\n","model.add(SimpleRNN(100))\n","#model.add(SimpleRNN(50, return_sequences=True))\n","#model.add(SimpleRNN(50))\n","#model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","print(\"Model created.\")"],"metadata":{"id":"qCq8izxlJCdI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model and define the loss and optimization functions\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","print(\"Model compiled, ready to be fit to the training data.\")"],"metadata":{"id":"P3V82YolJN89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the different layers in the model\n","print(model.summary())"],"metadata":{"id":"1q58xK99Jb1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit the model to the training data\n","model.fit(X_train, y_train, epochs=4, batch_size=64)"],"metadata":{"id":"K6Smzw8eJPoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the trained model on the test data\n","model_scores = model.evaluate(X_test, y_test, verbose=0)\n","\n","# Print out the accuracy of the model on the test set\n","print(\"Model accuracy on the test dataset: {0:.2f}%\".format(model_scores[1]*100))"],"metadata":{"id":"Gv3MxnRaJuPK"},"execution_count":null,"outputs":[]}]}